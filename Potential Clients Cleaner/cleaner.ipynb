{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de Clientes Potenciales en Bogotá\n",
    "La idea de este script es limpiar los clientes potenciales en bogotá siguiendo estas reglas:\n",
    "\n",
    "## Limpieza de clientes potenciales por cercania de PIN.\n",
    "- Se va a evaluar el geohash de 9 digitos de cada uno de los clientes potenciales, esto es el equivalente a un recuadro de 5x5m en un mapa. Si este recuadro hace match con el geohash de algún otro cliente, entonces se borra.\n",
    "\n",
    "## Limpieza de potenciales por CRM\n",
    "- No es claro como usar el CRM para limpiar clientes potenciales pues los clientes potenciales no tienen CRM.\n",
    "\n",
    "## Limpieza de potenciales por base de llamadas\n",
    "- Se llamaron a los clientes potenciales y se les hizo preguntas. Si la rta es que ya están registrados en al app, se eliminan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se obtiene la base de clientes con el siguiente codigo sql en Snowflake\n",
    "\n",
    "~~~sql\n",
    "SELECT \n",
    "      id,\n",
    "      source_client,\n",
    "      latitude,\n",
    "      longitude\n",
    "FROM \n",
    "    \"ANALYTICS\".\"PROD_MODELED\".\"CLIENTS\"\n",
    "WHERE source_country = 'COLOMBIA'\n",
    "    and warehouse = 'bodega Fontibon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geohash\n",
    "import math\n",
    "\n",
    "clients_base = pd.read_csv('clients_base_fontibon.csv').to_dict(orient = 'index')\n",
    "drops = []\n",
    "\n",
    "GeoHash_MotoTul = set()\n",
    "GeoHash_Clients = set()\n",
    "\n",
    "for i in clients_base:\n",
    "    if ( math.isnan(clients_base[i]['lat']) or math.isnan(clients_base[i]['lng'])):\n",
    "        drops.append(i)\n",
    "    else:\n",
    "        try:\n",
    "            _9GeoHash = geohash.encode(clients_base[i]['lat'], clients_base[i]['lng'], 9)\n",
    "            clients_base[i]['hash'] = _9GeoHash\n",
    "            if clients_base[i]['source_client'] == 'Client':\n",
    "                GeoHash_Clients.add(_9GeoHash)\n",
    "            else:\n",
    "                GeoHash_MotoTul.add(_9GeoHash)\n",
    "        except:\n",
    "            print(clients_base[i])\n",
    "\n",
    "d = GeoHash_Clients.intersection(GeoHash_MotoTul)\n",
    "\n",
    "for i in clients_base:\n",
    "    if i in drops:\n",
    "        pass\n",
    "    else:\n",
    "        if (clients_base[i]['hash'] in d and clients_base[i]['source_client'] == 'MotoTul') :\n",
    "            drops.append(i)\n",
    "\n",
    "mototul_ids = []\n",
    "for i in drops:\n",
    "    mototul_ids.append(clients_base[i]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('zone_clean.json', 'w') as fp:\n",
    "    json.dump(mototul_ids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = [922,\n",
    "1359,\n",
    "1391,\n",
    "1400,\n",
    "1402,\n",
    "1424,\n",
    "1425,\n",
    "1451,\n",
    "1458,\n",
    "1479,\n",
    "1511,\n",
    "1528,\n",
    "1556,\n",
    "1558,\n",
    "1609,\n",
    "1614,\n",
    "1623,\n",
    "1625,\n",
    "1659,\n",
    "1679,\n",
    "1682,\n",
    "1708,\n",
    "1714,\n",
    "1731,\n",
    "1735,\n",
    "1741,\n",
    "1744,\n",
    "1751,\n",
    "1802,\n",
    "1819,\n",
    "1845,\n",
    "1863,\n",
    "1864,\n",
    "1936,\n",
    "1949,\n",
    "2028,\n",
    "2137,\n",
    "2323,\n",
    "2356,\n",
    "2358,\n",
    "2377,\n",
    "2393,\n",
    "2412,\n",
    "2440,\n",
    "2445,\n",
    "2449,\n",
    "2460,\n",
    "2501,\n",
    "2526,\n",
    "2582,\n",
    "2611,\n",
    "2612,\n",
    "2618,\n",
    "2638,\n",
    "2643,\n",
    "2662,\n",
    "2668,\n",
    "2675,\n",
    "2676,\n",
    "2679,\n",
    "2683,\n",
    "2689,\n",
    "2707,\n",
    "2708,\n",
    "2722,\n",
    "2779,\n",
    "2781,\n",
    "2788,\n",
    "2827,\n",
    "2828,\n",
    "2829,\n",
    "2831,\n",
    "2851,\n",
    "2853,\n",
    "2857,\n",
    "2858,\n",
    "2864,\n",
    "2865,\n",
    "2869,\n",
    "2898,\n",
    "2908,\n",
    "2920,\n",
    "2926,\n",
    "2958,\n",
    "2978,\n",
    "2988,\n",
    "2995,\n",
    "3005,\n",
    "3008,\n",
    "3023,\n",
    "3034,\n",
    "3090,\n",
    "3097,\n",
    "3102,\n",
    "3107,\n",
    "3110,\n",
    "3146,\n",
    "3171,\n",
    "3178,\n",
    "3218,\n",
    "3219,\n",
    "3276,\n",
    "3310,\n",
    "3397,\n",
    "3415,\n",
    "3657,\n",
    "3664,\n",
    "3679,\n",
    "3685,\n",
    "3694,\n",
    "3701,\n",
    "3706,\n",
    "3707,\n",
    "3708,\n",
    "3709,\n",
    "3710,\n",
    "3719,\n",
    "3722,\n",
    "3724,\n",
    "3726,\n",
    "3728,\n",
    "3739,\n",
    "3740,\n",
    "3743,\n",
    "3745,\n",
    "3747,\n",
    "3753,\n",
    "3754,\n",
    "3756,\n",
    "3757,\n",
    "3758,\n",
    "3759,\n",
    "3760,\n",
    "3765,\n",
    "3817,\n",
    "3891,\n",
    "3954,\n",
    "3959,\n",
    "3962,\n",
    "3966,\n",
    "3970,\n",
    "3974,\n",
    "3976,\n",
    "3979,\n",
    "3992,\n",
    "4003,\n",
    "4015]\n",
    "\n",
    "with open('calls_clean.json', 'w') as fp:\n",
    "    json.dump(calls, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "937962e8a5a784c1118c67fdadb893054edd6cc43e6c682dcaf01709dfd34737"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
