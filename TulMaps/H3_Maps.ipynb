{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnología H3 Uber\n",
    "Diferentes resoluciones para diferentes aplicaciones\n",
    "\n",
    "| H3 Resolution | Average Hexagon Area (km<sup>2</sup>) | Average Hexagon Edge Length (km) | Number of unique indexes |\n",
    "| ------------- | ------------------------------------- | -------------------------------- | ------------------------ |\n",
    "| 7             | 5.1612932                             | 1.220629759                      | 98,825,162               |\n",
    "| 8             | 0.7373276                             | 0.461354684                      | 691,776,122              |\n",
    "| 9             | 0.1053325                             | 0.174375668                      | 4,842,432,842            |\n",
    "| 10            | 0.0150475                             | 0.065907807                      | 33,897,029,882           |\n",
    "| 11            | 0.0021496                             | 0.024910561                      | 237,279,209,162          |\n",
    "| 12            | 0.0003071                             | 0.009415526                      | 1,660,954,464,122        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "\n",
    "# Write data into Snowflake table\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "\n",
    "#----------CONNECTION TO SNOWFLAKE-------------\n",
    "SF_ACCOUNT = 'gfa04036.us-east-1'\n",
    "SF_WH = 'TRANSFORMING'\n",
    "SF_USERNAME = 'DBT_USER'\n",
    "SF_PASSWORD = '2C>`8Q!8y*Sz]h/):Xxy&WNJv'\n",
    "\n",
    "# Connecting to Snowflake using the default authenticator\n",
    "ctx = snowflake.connector.connect(\n",
    "  user=SF_USERNAME,    #username,\n",
    "  password=SF_PASSWORD,    #password,\n",
    "  account=SF_ACCOUNT,\n",
    "  warehouse=SF_WH,\n",
    "  database='ANALYTICS',\n",
    "  schema='PROD_STAGING'\n",
    ")\n",
    "\n",
    "cur=ctx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74063\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "cur=ctx.cursor()\n",
    "\n",
    "# Lets aggregate the metering data for Dominion Power up to the day level\n",
    "#sql = \"select date_trunc('day', STARTTIME), count(*) from trips_vw\" +\\\n",
    "#        \" group by date_trunc('day', STARTTIME)\" +\\\n",
    "#        \" order by date_trunc('day', STARTTIME)\"\n",
    "sql =   \"\"\"\n",
    "        SELECT\n",
    "            uuid,\n",
    "            source_country,\n",
    "            'Ironmongery' AS source_address,\n",
    "            latitude AS lat,\n",
    "            longitude AS lng\n",
    "        FROM ANALYTICS.PROD_STAGING.STG_IRONMONGERIES\n",
    "        WHERE latitude IS NOT NULL\n",
    "            AND longitude IS NOT NULL\n",
    "            AND latitude != 0\n",
    "            AND longitude != 0 \n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            uuid,\n",
    "            source_country,\n",
    "            'Address' AS source_address,\n",
    "            latitude AS lat,\n",
    "            longitude AS lng\n",
    "        FROM ANALYTICS.PROD_STAGING.STG_CLIENT_ADDRESSES\n",
    "        WHERE latitude IS NOT NULL\n",
    "            AND longitude IS NOT NULL\n",
    "            AND latitude != 0\n",
    "            AND longitude != 0 \n",
    "        \"\"\"\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the Pandas DataFrame.\n",
    "clients = cur.fetch_pandas_all()\n",
    "clients.reset_index(inplace=True)\n",
    "clients = clients.to_dict(orient = 'index')\n",
    "\n",
    "# For each client, try to write the cell\n",
    "for i in clients:\n",
    "    clients[i]['r1_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 1)\n",
    "    clients[i]['r2_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 2)\n",
    "    clients[i]['r3_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 3)\n",
    "    clients[i]['r4_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 4)\n",
    "    clients[i]['r5_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 5)\n",
    "    clients[i]['r6_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 6)\n",
    "    clients[i]['r7_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 7)\n",
    "    clients[i]['r8_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 8)\n",
    "    clients[i]['r9_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 9)\n",
    "    clients[i]['r10_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 10)\n",
    "    clients[i]['r11_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 11)\n",
    "    clients[i]['r12_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 12)\n",
    "    clients[i]['r13_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 13)\n",
    "    clients[i]['r14_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 14)\n",
    "    clients[i]['r15_h3'] = h3.geo_to_h3(clients[i]['LAT'], clients[i]['LNG'], 15)\n",
    "\n",
    "print(len(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing 10000 records:  10000\n",
      "Flushing 10000 records:  20000\n",
      "Flushing 10000 records:  30000\n",
      "Flushing 10000 records:  40000\n",
      "Flushing 10000 records:  50000\n",
      "Flushing 10000 records:  60000\n",
      "Flushing 10000 records:  70000\n",
      "Records updated successfully 74063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = snowflake.connector.connect(\n",
    "  user=SF_USERNAME,    #username,\n",
    "  password=SF_PASSWORD,    #password,\n",
    "  account=SF_ACCOUNT,\n",
    "  warehouse=SF_WH,\n",
    "  database='ANALYTICS',\n",
    "  schema='PROD_STAGING'\n",
    ")\n",
    "\n",
    "cur=ctx.cursor()\n",
    "sql = \"\"\" CREATE OR REPLACE TABLE stg_py_address_h3_cells (\n",
    "                source_country varchar(1020),\n",
    "                source_address varchar(1020),\n",
    "                uuid varchar(1020),\n",
    "                r1_h3  varchar(1020),\n",
    "                r2_h3  varchar(1020),\n",
    "                r3_h3  varchar(1020),\n",
    "                r4_h3  varchar(1020),\n",
    "                r5_h3  varchar(1020),\n",
    "                r6_h3  varchar(1020),\n",
    "                r7_h3  varchar(1020),\n",
    "                r8_h3  varchar(1020),\n",
    "                r9_h3  varchar(1020),\n",
    "                r10_h3 varchar(1020),\n",
    "                r11_h3 varchar(1020),\n",
    "                r12_h3 varchar(1020),\n",
    "                r13_h3 varchar(1020),\n",
    "                r14_h3 varchar(1020),\n",
    "                r15_h3 varchar(1020)) \"\"\"\n",
    "\n",
    "cur.execute(sql)\n",
    "#DataFrame of the needed results to update in the same orde\n",
    "# multiple records to be updated in tuple format\n",
    "sql = \"INSERT INTO stg_py_address_h3_cells VALUES\"\n",
    "count = 0\n",
    "for i in clients:\n",
    "    count += 1\n",
    "    sql += \"(\" \\\n",
    "            + \"'\" + clients[i]['SOURCE_COUNTRY'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['SOURCE_ADDRESS'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['UUID'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r1_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r2_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r3_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r4_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r5_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r6_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r7_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r8_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r9_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r10_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r11_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r12_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r13_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r14_h3'] + \"'\" + \",\" \\\n",
    "            + \"'\" + clients[i]['r15_h3'] + \"'\" \\\n",
    "            + \")\"\n",
    "    if (count % 10000 == 0):\n",
    "                cur.execute(sql)\n",
    "                print(\"Flushing 10000 records: \", count)\n",
    "                sql = \"INSERT INTO stg_py_address_h3_cells VALUES \"\n",
    "    else:\n",
    "        if count < len(clients):\n",
    "            sql += \",\"\n",
    "\n",
    "cur.execute(sql)    \n",
    "print(\"Records updated successfully\", count)\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "distinctCells = set()\n",
    "resolution = 'r7_h3'\n",
    "for i in clients:\n",
    "    distinctCells.add(clients[i][resolution])\n",
    "\n",
    "# Generación de sub-mapas, uno global\n",
    "listFeatures = []\n",
    "for i in distinctCells:\n",
    "    hexagon = h3.h3_to_geo_boundary(i, geo_json=True)\n",
    "    listFeatures.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"Cell\":  i\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": [hexagon]\n",
    "    }})\n",
    "\n",
    "with open('r7_cells'+'.geojson', 'w') as fp:\n",
    "    json.dump({\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": resolution,\n",
    "        \"crs\": { \"type\": \"name\", \"properties\": { \"name\": resolution+'cells' } },\n",
    "        \"features\": listFeatures}\n",
    "    , fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "937962e8a5a784c1118c67fdadb893054edd6cc43e6c682dcaf01709dfd34737"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
