{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Anomaly detection algorithms\n",
    "\n",
    "Los outliers en el problema de zonificación son aquellos clientes alejados del grupo grande de ubicaciones, usualmente se encuentran en zonas alejadas a la ciudad → poblaciones. Estos clientes se remueven de la zonificación pues no siguen la lógica de este proceso.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/0.20/_images/sphx_glr_plot_anomaly_comparison_001.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "Para nuestro caso de estudio los métodos One-Class SVM, Isolation Forest y Local Outlier Factor son factibles. Robust covariance no pues obliga a uqe los datos se distribuya como una elipse y eso depende de la ciudad."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "matplotlib.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "# DataSets\n",
    "files = ['fontibon.csv', 'quito.csv', 'tlalnepantla.csv', 'cali.csv', 'bucaramanga.csv']\n",
    "datasets = []\n",
    "\n",
    "for i in files:\n",
    "    df = pd.read_csv(i)\n",
    "    df.dropna()\n",
    "    df = df.to_dict(orient = 'index')\n",
    "    datasets.append( np.array([ [df[j]['lng'], df[j]['lat']] for j in df ]) )\n",
    "\n",
    "# Detection algorithmn with different gamma value\n",
    "anomaly_algorithms = [\n",
    "    (\"One-Class SVM 0.1\", svm.OneClassSVM(kernel=\"rbf\",gamma=0.1)),\n",
    "    (\"Robust covariance\", EllipticEnvelope()),\n",
    "    (\"Isolation Forest\", IsolationForest(random_state=42)),\n",
    "    (\"Local Outlier Factor\", LocalOutlierFactor(n_neighbors=35))\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(len(anomaly_algorithms) * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "for i_dataset, X in enumerate(datasets):\n",
    "    for name, algorithm in anomaly_algorithms:\n",
    "        \n",
    "        plt.subplot(len(datasets), len(anomaly_algorithms), plot_num)\n",
    "        \n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=15)\n",
    "\n",
    "        # fit the data and tag outliers\n",
    "        if name == \"Local Outlier Factor\":\n",
    "            y_pred = algorithm.fit_predict(X)\n",
    "        else:\n",
    "            y_pred = algorithm.fit(X).predict(X)\n",
    "        \n",
    "        colors = np.array(['#377eb8', '#ff7f00'])\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[(y_pred + 1) // 2])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Not plotting outliers\n",
    "\n",
    "plt.figure(figsize=(len(anomaly_algorithms) * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "for i_dataset, X in enumerate(datasets):\n",
    "    for name, algorithm in anomaly_algorithms:\n",
    "        \n",
    "        plt.subplot(len(datasets), len(anomaly_algorithms), plot_num)\n",
    "        \n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=15)\n",
    "\n",
    "        # fit the data and tag outliers\n",
    "        if name == \"Local Outlier Factor\":\n",
    "            y_pred = algorithm.fit_predict(X)\n",
    "        else:\n",
    "            y_pred = algorithm.fit(X).predict(X)\n",
    "        \n",
    "        newX = []\n",
    "        for idx, k in enumerate(y_pred):\n",
    "            if k == 1:\n",
    "                newX.append(X[idx])\n",
    "                \n",
    "        newX = np.array(newX)\n",
    "        \n",
    "        colors = np.array(['#377eb8', '#ff7f00'])\n",
    "        plt.scatter(newX[:, 0], newX[:, 1], s=10, color=colors[1])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DataSets\n",
    "files = ['fontibon.csv', 'quito.csv', 'tlalnepantla.csv', 'cali.csv', 'bucaramanga.csv']\n",
    "datasets = []\n",
    "\n",
    "for i in files:\n",
    "    df = pd.read_csv(i)\n",
    "    df.dropna()\n",
    "    df = df.to_dict(orient = 'index')\n",
    "    datasets.append( np.array([ [df[j]['lng'], df[j]['lat']] for j in df ]) )\n",
    "\n",
    "# Detection algorithmn with different gamma value\n",
    "anomaly_algorithms = [\n",
    "    (\"I. Forest 0.05\", IsolationForest(contamination=0.05, random_state=42)),\n",
    "    (\"I. Forest 0.10\", IsolationForest(contamination=0.10, random_state=42)),\n",
    "    (\"I. Forest 0.20\", IsolationForest(contamination=0.20, random_state=42)),\n",
    "    (\"I. Forest 0.30\", IsolationForest(contamination=0.30, random_state=42)),\n",
    "    (\"I. Forest 0.40\", IsolationForest(contamination=0.40, random_state=42)),\n",
    "    (\"I. Forest 0.50\", IsolationForest(contamination=0.50, random_state=42))\n",
    "]\n",
    "\n",
    "# Not plotting outliers\n",
    "plt.figure(figsize=(len(anomaly_algorithms) * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "for i_dataset, X in enumerate(datasets):\n",
    "    for name, algorithm in anomaly_algorithms:\n",
    "        \n",
    "        plt.subplot(len(datasets), len(anomaly_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=15)\n",
    "\n",
    "        # fit the data and tag outliers\n",
    "        if name == \"Local Outlier Factor\":\n",
    "            y_pred = algorithm.fit_predict(X)\n",
    "        else:\n",
    "            y_pred = algorithm.fit(X).predict(X)\n",
    "        \n",
    "        newX = []\n",
    "        for idx, k in enumerate(y_pred):\n",
    "            if k == 1:\n",
    "                newX.append(X[idx])\n",
    "                \n",
    "        newX = np.array(newX)\n",
    "        \n",
    "        colors = np.array(['#377eb8', '#ff7f00'])\n",
    "        plt.scatter(newX[:, 0], newX[:, 1], s=10, color=colors[1])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering\r\n",
    "\r\n",
    "Una vez se eliminan los datos atipicos de direcciones se sigue con el problema de zonificación o clusterización. Para este problema el equipo comercial define cuántas zonas quiere obtener, ya sea por el # de hunters que tiene en el momento, o por el # de hunters que se planean contratar.\r\n",
    "\r\n",
    "Se tiene que tener en cuenta que aquellos outliers removidos en la fase anterior no se van a tener en cuenta en el nuevo ruteo ni van a contar en el número de zonas definidas por comercial."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def objectiveFun(df: dict, n) -> int:\n",
    "    F_OB = { i: 0 for i in range(n)}\n",
    "    for i in df:\n",
    "        F_OB[df[i]['zone']] += 1\n",
    "\n",
    "    nMax = max([F_OB[i] for i in F_OB])\n",
    "    nMin = min([F_OB[i] for i in F_OB])\n",
    "    \n",
    "    return nMax,nMin"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "contaminationLS = np.arange(0.1,0.5,0.05) # Diferent outliers filtering by Isolation Forest\n",
    "nClusters = 30\n",
    "\n",
    "# Not plotting outliers\n",
    "plt.figure(figsize=(22, 26))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.02, top=.96, wspace=.05,hspace=.12)\n",
    "\n",
    "plot_num = 1\n",
    "for contamination in contaminationLS:\n",
    "    start_time = time.time()\n",
    "    # Test case - Bodega Fontibon\n",
    "    df = pd.read_csv('fontibonCPS.csv')\n",
    "    df.dropna()\n",
    "    df = df.to_dict(orient = 'index')\n",
    "\n",
    "    X = []\n",
    "    IdK = {}\n",
    "    count = 0\n",
    "    for j in df:\n",
    "        X.append([df[j]['lng'], df[j]['lat']])\n",
    "        IdK[count] = j\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "    outliers_algh = IsolationForest(contamination = contamination) # IsolationForest Algorithm\n",
    "\n",
    "    ''' Outliers remover '''\n",
    "    y_pred = outliers_algh.fit(X).predict(X) # Fit algorithm in data\n",
    "    for idx, k in enumerate(y_pred):\n",
    "        if k == -1:\n",
    "            df.pop(IdK[idx])\n",
    "\n",
    "    # Clean Data\n",
    "    X = []\n",
    "    IdK = {}\n",
    "    count = 0\n",
    "    for j in df:\n",
    "        X.append([df[j]['lng'], df[j]['lat']])\n",
    "        IdK[count] = j\n",
    "        count += 1\n",
    "    X = np.array(X)\n",
    "\n",
    "    ''' Zonification '''\n",
    "\n",
    "    from sklearn import cluster, mixture\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    clustering_alorithms = [\n",
    "        ('ward' , cluster.AgglomerativeClustering(n_clusters=nClusters, linkage='ward')),\n",
    "        ('average' , cluster.AgglomerativeClustering(n_clusters=nClusters, linkage='average')),\n",
    "        ('complete' , cluster.AgglomerativeClustering(n_clusters=nClusters, linkage='complete')),\n",
    "        ('single' , cluster.AgglomerativeClustering(n_clusters=nClusters, linkage='single')),\n",
    "        ('kMeans' , cluster.KMeans(nClusters)),\n",
    "        ('spectral nn' , cluster.SpectralClustering(n_clusters=nClusters, eigen_solver='arpack', affinity=\"nearest_neighbors\")),\n",
    "        ('spectal rbf' , cluster.SpectralClustering(n_clusters=nClusters, eigen_solver='arpack', affinity=\"rbf\")),\n",
    "        ('birch' , cluster.Birch(n_clusters=nClusters, threshold=0)),\n",
    "        ('gaussian' , mixture.GaussianMixture(n_components=nClusters, covariance_type='full'))\n",
    "    ]\n",
    "\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    for name, algorithm in clustering_alorithms:\n",
    "        algorithm.fit(X)\n",
    "\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            z_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            z_pred = algorithm.predict(X)\n",
    "\n",
    "        for idx, k in enumerate(z_pred):\n",
    "            df[IdK[idx]]['zone'] = k\n",
    "\n",
    "        plt.subplot( 8, len(clustering_alorithms), plot_num)\n",
    "        plt.scatter( [df[i]['lng'] for i in df], [df[i]['lat'] for i in df], c = [df[i]['zone'] for i in df])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.title( name + str(round(contamination,2)) + str(objectiveFun(df,30)))\n",
    "        plot_num += 1"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}